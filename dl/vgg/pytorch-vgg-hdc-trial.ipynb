{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "291c62c0-d60a-44c6-aef5-cb1917782e7d",
   "metadata": {},
   "source": [
    "# CNN + FSL\n",
    "- In this example we will explore the combination of using CNN layers of VGG16 and HDC for classification\n",
    "- This is a conceptual replication of the work in https://arxiv.org/abs/2409.10918\n",
    "- Take note that we had to pretrain a quantized VGG16 for this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00856eb5-2d21-4d01-babc-b97760649f2d",
   "metadata": {},
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2175dca6-e472-4bb6-8606-a05fca6d5232",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:57:27.785773Z",
     "iopub.status.busy": "2025-05-29T18:57:27.785349Z",
     "iopub.status.idle": "2025-05-29T18:57:35.941396Z",
     "shell.execute_reply": "2025-05-29T18:57:35.940488Z",
     "shell.execute_reply.started": "2025-05-29T18:57:27.785740Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vgg16\n",
    "from torch.quantization import QuantStub, DeQuantStub\n",
    "import torch.quantization\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "from vgg_models import QuantizableVGG16\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cfb86d-d9be-4b50-8d2b-2efb6f829dd4",
   "metadata": {},
   "source": [
    "# Importing the Model\n",
    "- The model can be changed but for this experiment I had to use this one I pretrained before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc56d946-6757-45a1-bc1c-4013ca76faa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:57:35.943476Z",
     "iopub.status.busy": "2025-05-29T18:57:35.943059Z",
     "iopub.status.idle": "2025-05-29T18:57:41.062981Z",
     "shell.execute_reply": "2025-05-29T18:57:41.062063Z",
     "shell.execute_reply.started": "2025-05-29T18:57:35.943447Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/micas/rantonio/anaconda3/envs/torchx/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/users/micas/rantonio/anaconda3/envs/torchx/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/users/micas/rantonio/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "/users/micas/rantonio/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/ao/quantization/observer.py:1318: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = QuantizableVGG16(num_classes=100)\n",
    "\n",
    "# Prepare for quantized loading\n",
    "model.eval()  # Important for quantization\n",
    "model.fuse_model()\n",
    "model.qconfig = torch.quantization.get_default_qconfig(\"fbgemm\")\n",
    "torch.quantization.prepare(model, inplace=True)\n",
    "torch.quantization.convert(model, inplace=True)\n",
    "\n",
    "# Wrap in DataParallel to match saved state dict\n",
    "model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b54e29-d2b2-494a-90a9-f387eee5d03e",
   "metadata": {},
   "source": [
    "The loading below should say that all keys match. If not, consider making sure your models match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d0640c3-ecae-46ff-8afb-a2b7d7d8eb50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:57:41.064439Z",
     "iopub.status.busy": "2025-05-29T18:57:41.064069Z",
     "iopub.status.idle": "2025-05-29T18:57:42.108927Z",
     "shell.execute_reply": "2025-05-29T18:57:42.108166Z",
     "shell.execute_reply.started": "2025-05-29T18:57:41.064411Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/micas/rantonio/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/_utils.py:431: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  device=storage.device,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load quantized state_dict\n",
    "state_dict = torch.load(\"quantized_vgg16_cifar100.pth\", map_location='cpu')\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95562d7b-3626-4f31-901f-24f0c7426433",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:57:42.110843Z",
     "iopub.status.busy": "2025-05-29T18:57:42.110491Z",
     "iopub.status.idle": "2025-05-29T18:57:43.896460Z",
     "shell.execute_reply": "2025-05-29T18:57:43.895012Z",
     "shell.execute_reply.started": "2025-05-29T18:57:42.110815Z"
    }
   },
   "outputs": [],
   "source": [
    "quantized_model = torch.quantization.convert(model, inplace=False)\n",
    "quantized_model = quantized_model.module  # unwrap from DataParallel\n",
    "quantized_model.eval()\n",
    "quantized_model.to('cpu');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00c33d7-5656-48dd-9f90-30fcb05e6faf",
   "metadata": {},
   "source": [
    "# Function Hook\n",
    "- This is used to extract the output done on the final max-pool layer of the CNN block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b5533d7-899e-4229-ae10-f579f7ccf1c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:57:43.898378Z",
     "iopub.status.busy": "2025-05-29T18:57:43.897965Z",
     "iopub.status.idle": "2025-05-29T18:57:43.906014Z",
     "shell.execute_reply": "2025-05-29T18:57:43.904910Z",
     "shell.execute_reply.started": "2025-05-29T18:57:43.898343Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7f7349963e20>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Placeholder for feature map\n",
    "activation = {}\n",
    "\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "# Register hook at the desired layer (e.g., layer 30)\n",
    "layer_index = 30  # verify this with print(model.features)\n",
    "quantized_model.features[layer_index].register_forward_hook(get_activation('last_maxpool'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9fe4b2-528b-4da5-be26-fa9dd95076c7",
   "metadata": {},
   "source": [
    "# Download CIFAR-100 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5188287f-1215-480d-becf-9208f0a8919d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:57:43.907416Z",
     "iopub.status.busy": "2025-05-29T18:57:43.907085Z",
     "iopub.status.idle": "2025-05-29T18:57:44.721637Z",
     "shell.execute_reply": "2025-05-29T18:57:44.720508Z",
     "shell.execute_reply.started": "2025-05-29T18:57:43.907389Z"
    }
   },
   "outputs": [],
   "source": [
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5071, 0.4865, 0.4409],\n",
    "                         std=[0.2673, 0.2564, 0.2762])\n",
    "])\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                        download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                         shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ec3205-5200-4196-ac7e-55e6f3e3a893",
   "metadata": {},
   "source": [
    "# Some Useful Functions\n",
    "- `get_n_samples_per_class`: Used to get n samples per class.\n",
    "- `project_qhv`: Used to project a CNN feature vector into a query HV. It is already signed at the end.\n",
    "- `sim_search`: Used to do similarity search and return the similarity score and target label value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84d6b0a5-7324-46e0-88a4-d6069a5ec9a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:57:44.723152Z",
     "iopub.status.busy": "2025-05-29T18:57:44.722761Z",
     "iopub.status.idle": "2025-05-29T18:57:44.728705Z",
     "shell.execute_reply": "2025-05-29T18:57:44.727962Z",
     "shell.execute_reply.started": "2025-05-29T18:57:44.723122Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_n_samples_per_class(dataset, N):\n",
    "    class_samples = defaultdict(list)\n",
    "    class_counts = defaultdict(int)\n",
    "\n",
    "    num_classes = len(dataset.classes)\n",
    "\n",
    "    # tqdm wraps the iterable to show progress\n",
    "    for sample, label in tqdm(dataset, desc=\"Collecting samples\"):\n",
    "        if class_counts[label] < N:\n",
    "            class_samples[label].append((sample, label))\n",
    "            class_counts[label] += 1\n",
    "\n",
    "        # Stop early if we have enough samples for all classes\n",
    "        if all(class_counts[c] >= N for c in range(num_classes)):\n",
    "            break\n",
    "\n",
    "    return dict(class_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "526eb441-9ac2-4daa-adec-e894a7c198ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T19:06:44.864241Z",
     "iopub.status.busy": "2025-05-29T19:06:44.863720Z",
     "iopub.status.idle": "2025-05-29T19:06:44.868865Z",
     "shell.execute_reply": "2025-05-29T19:06:44.868141Z",
     "shell.execute_reply.started": "2025-05-29T19:06:44.864207Z"
    }
   },
   "outputs": [],
   "source": [
    "def project_qhv(query_v, projection_matrix):\n",
    "    # First pass through the model the samples\n",
    "    # Class, item #, tensor is at [0]\n",
    "    output = quantized_model(query_v)\n",
    "    # Get the output\n",
    "    intermediate_output = activation['last_maxpool']\n",
    "    # Get the values and put to float first\n",
    "    int_values = intermediate_output.int_repr().float()\n",
    "    # Flatten\n",
    "    flattened = int_values.reshape(1, -1)  # shape: [1, 25088]\n",
    "    # Do random projection\n",
    "    projected = flattened @ projection_matrix  # shape: [1, 512]\n",
    "    return projected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "813baa29-aa70-49d1-b9fd-c1516464248c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T19:05:54.236204Z",
     "iopub.status.busy": "2025-05-29T19:05:54.235687Z",
     "iopub.status.idle": "2025-05-29T19:05:54.241424Z",
     "shell.execute_reply": "2025-05-29T19:05:54.240502Z",
     "shell.execute_reply.started": "2025-05-29T19:05:54.236169Z"
    }
   },
   "outputs": [],
   "source": [
    "def sim_search(class_hvs, q_hv):\n",
    "    sim_score = -2\n",
    "    target_label = -9\n",
    "    for i in range(len(class_hvs)):\n",
    "        cos_sim  = F.cosine_similarity(q_hv, class_hvs[i], dim=1)\n",
    "        if cos_sim > sim_score:\n",
    "            sim_score = cos_sim\n",
    "            target_label = i\n",
    "    return sim_score, target_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a7c7c2-c03d-486e-bc2f-2a8ec958f93c",
   "metadata": {},
   "source": [
    "# Get Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d16520ac-b825-4674-ae45-99fd5889fd8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:57:45.004512Z",
     "iopub.status.busy": "2025-05-29T18:57:45.004077Z",
     "iopub.status.idle": "2025-05-29T18:58:00.429521Z",
     "shell.execute_reply": "2025-05-29T18:58:00.426445Z",
     "shell.execute_reply.started": "2025-05-29T18:57:45.004482Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting samples: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉| 9999/10000 [00:15<00:00, 648.92it/s]\n"
     ]
    }
   ],
   "source": [
    "MAX_SAMPLES = 100\n",
    "samples_per_class = get_n_samples_per_class(testset, MAX_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3dd9cc8-addc-45ff-b30d-ece4857a631f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:58:00.434990Z",
     "iopub.status.busy": "2025-05-29T18:58:00.434212Z",
     "iopub.status.idle": "2025-05-29T18:58:00.444909Z",
     "shell.execute_reply": "2025-05-29T18:58:00.444223Z",
     "shell.execute_reply.started": "2025-05-29T18:58:00.434908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 samples: 100\n",
      "Class 1 samples: 100\n",
      "Class 99 samples: 100\n"
     ]
    }
   ],
   "source": [
    "# Check how many samples collected for class 0 and 1\n",
    "print(f\"Class 0 samples: {len(samples_per_class[0])}\")\n",
    "print(f\"Class 1 samples: {len(samples_per_class[1])}\")\n",
    "print(f\"Class 99 samples: {len(samples_per_class[99])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98ab99b7-74f4-4895-83ef-7721ac3dae36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:58:00.446017Z",
     "iopub.status.busy": "2025-05-29T18:58:00.445747Z",
     "iopub.status.idle": "2025-05-29T18:58:00.453095Z",
     "shell.execute_reply": "2025-05-29T18:58:00.452369Z",
     "shell.execute_reply.started": "2025-05-29T18:58:00.445989Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_per_class[0][0][0].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903b7479-874a-40a3-b8a3-2fcf88ed66d4",
   "metadata": {},
   "source": [
    "# Make Projection Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4be5c2ba-27f7-4d90-85ee-da83b7791c75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:58:00.454803Z",
     "iopub.status.busy": "2025-05-29T18:58:00.454437Z",
     "iopub.status.idle": "2025-05-29T18:58:00.685787Z",
     "shell.execute_reply": "2025-05-29T18:58:00.684938Z",
     "shell.execute_reply.started": "2025-05-29T18:58:00.454774Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25088, 512])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the dimensions\n",
    "input_dim = 25088   # e.g., 512 channels × 7 × 7\n",
    "output_dim = 512    # your projected size\n",
    "\n",
    "# Randomly generate +1 and -1 entries\n",
    "projection_matrix = (torch.randint(0, 2, (input_dim, output_dim)) * 2 - 1).float()  # values: [0, 1] → [−1, 1]\n",
    "projection_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987febf3-f628-442f-9290-c89c11e19967",
   "metadata": {},
   "source": [
    "# HDC Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "463a29aa-9ccd-42b9-8644-0c022d0f48e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T19:31:15.528679Z",
     "iopub.status.busy": "2025-05-29T19:31:15.528266Z",
     "iopub.status.idle": "2025-05-29T19:36:22.270295Z",
     "shell.execute_reply": "2025-05-29T19:36:22.269288Z",
     "shell.execute_reply.started": "2025-05-29T19:31:15.528652Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing classes: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [05:06<00:00,  3.07s/it]\n"
     ]
    }
   ],
   "source": [
    "# Some fixed parameters\n",
    "NUM_CLASSES = 100\n",
    "HV_DIM = 512\n",
    "NUM_TRAIN_SAMPLES = 50\n",
    "\n",
    "# Initialize class HVs\n",
    "class_hvs_bin = {}\n",
    "class_hvs_int = {}\n",
    "\n",
    "# Iterate per class with tqdm\n",
    "for class_set in tqdm(range(NUM_CLASSES), desc=\"Processing classes\"):\n",
    "\n",
    "    # Initialize class hv\n",
    "    class_hv = torch.zeros(HV_DIM)\n",
    "\n",
    "    for item in range(NUM_TRAIN_SAMPLES):\n",
    "        query_v = samples_per_class[class_set][item][0].unsqueeze(0)\n",
    "        projected = project_qhv(query_v, projection_matrix)\n",
    "        class_hv = class_hv + projected\n",
    "\n",
    "    label = samples_per_class[class_set][0][1]\n",
    "    class_hvs_int[label] = class_hv\n",
    "\n",
    "    # Sign magnitude\n",
    "    class_hv_bin = torch.sign(class_hv)\n",
    "    class_hvs_bin[label] = class_hv_bin\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775b0c6e-8b7a-4780-b8ea-9f4977496523",
   "metadata": {},
   "source": [
    "# HDC Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88210f23-7297-45f5-92df-de6a5a7224ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T19:38:08.018734Z",
     "iopub.status.busy": "2025-05-29T19:38:08.018150Z",
     "iopub.status.idle": "2025-05-29T19:43:59.153568Z",
     "shell.execute_reply": "2025-05-29T19:43:59.152362Z",
     "shell.execute_reply.started": "2025-05-29T19:38:08.018677Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating classes: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [05:51<00:00,  3.51s/it]\n"
     ]
    }
   ],
   "source": [
    "START_NUM = NUM_TRAIN_SAMPLES\n",
    "MAX_SAMPLES = 100\n",
    "\n",
    "correct_qhv_int = 0\n",
    "correct_qhv_bin = 0\n",
    "\n",
    "for class_set in tqdm(range(NUM_CLASSES), desc=\"Evaluating classes\"):  \n",
    "    for item in range(NUM_TRAIN_SAMPLES):\n",
    "        projected = project_qhv(samples_per_class[class_set][item][0].unsqueeze(0), projection_matrix)\n",
    "        # Compare int style first\n",
    "        _, target_label_int = sim_search(class_hvs_int, projected)\n",
    "        # Compare bin style 2nd\n",
    "        projected_bin = torch.sign(projected)\n",
    "        _, target_label_bin = sim_search(class_hvs_bin, projected_bin)\n",
    "\n",
    "        if target_label_int == class_set:\n",
    "            correct_qhv_int += 1\n",
    "\n",
    "        if target_label_bin == class_set:\n",
    "            correct_qhv_bin += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8a983c6-1add-47c1-86d3-5baf050e096c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T19:48:14.122701Z",
     "iopub.status.busy": "2025-05-29T19:48:14.122226Z",
     "iopub.status.idle": "2025-05-29T19:48:14.128348Z",
     "shell.execute_reply": "2025-05-29T19:48:14.127560Z",
     "shell.execute_reply.started": "2025-05-29T19:48:14.122662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (int): 0.81\n",
      "Accuracy (bin): 0.58\n"
     ]
    }
   ],
   "source": [
    "TOTAL_TEST = (NUM_TRAIN_SAMPLES)*NUM_CLASSES\n",
    "accuracy_int = correct_qhv_int / TOTAL_TEST\n",
    "accuracy_bin = correct_qhv_bin / TOTAL_TEST\n",
    "print(f\"Accuracy (int): {accuracy_int:.2f}\")\n",
    "print(f\"Accuracy (bin): {accuracy_bin:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66bc5672-3de7-4595-8375-07e678e89d3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T19:50:23.062093Z",
     "iopub.status.busy": "2025-05-29T19:50:23.061532Z",
     "iopub.status.idle": "2025-05-29T19:56:18.930797Z",
     "shell.execute_reply": "2025-05-29T19:56:18.929334Z",
     "shell.execute_reply.started": "2025-05-29T19:50:23.062048Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating classes: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [05:55<00:00,  3.56s/it]\n"
     ]
    }
   ],
   "source": [
    "START_NUM = NUM_TRAIN_SAMPLES\n",
    "MAX_SAMPLES = 100\n",
    "\n",
    "correct_qhv_int = 0\n",
    "correct_qhv_bin = 0\n",
    "\n",
    "for class_set in tqdm(range(NUM_CLASSES), desc=\"Evaluating classes\"):  \n",
    "    for item in range(START_NUM, MAX_SAMPLES):\n",
    "        projected = project_qhv(samples_per_class[class_set][item][0].unsqueeze(0), projection_matrix)\n",
    "        # Compare int style first\n",
    "        _, target_label_int = sim_search(class_hvs_int, projected)\n",
    "        # Compare bin style 2nd\n",
    "        projected_bin = torch.sign(projected)\n",
    "        _, target_label_bin = sim_search(class_hvs_bin, projected_bin)\n",
    "\n",
    "        if target_label_int == class_set:\n",
    "            correct_qhv_int += 1\n",
    "\n",
    "        if target_label_bin == class_set:\n",
    "            correct_qhv_bin += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6f472dc-d286-4cac-bd93-d298e4c9ea75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T19:56:18.933793Z",
     "iopub.status.busy": "2025-05-29T19:56:18.933197Z",
     "iopub.status.idle": "2025-05-29T19:56:18.940917Z",
     "shell.execute_reply": "2025-05-29T19:56:18.939981Z",
     "shell.execute_reply.started": "2025-05-29T19:56:18.933734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (int): 0.49\n",
      "Accuracy (bin): 0.33\n"
     ]
    }
   ],
   "source": [
    "TOTAL_TEST = (MAX_SAMPLES - NUM_TRAIN_SAMPLES)*NUM_CLASSES\n",
    "accuracy_int = correct_qhv_int / TOTAL_TEST\n",
    "accuracy_bin = correct_qhv_bin / TOTAL_TEST\n",
    "print(f\"Accuracy (int): {accuracy_int:.2f}\")\n",
    "print(f\"Accuracy (bin): {accuracy_bin:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527fa8da-4ab4-4260-b0fb-9bc62b28e767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
