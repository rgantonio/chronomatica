{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb76134c-654f-425a-9982-8652580ab167",
   "metadata": {},
   "source": [
    "# Fine-tune Training VGG16 on CIFAR10\n",
    "- In this notebook, we will train the CIFAR-10 data set on VGG16\n",
    "- The problem is that the pre-trained model of VGG16 was for ImageNet not CIFAR10\n",
    "- This is an attempt to investigate and see how much accuracy VGG16 can achieve on this\n",
    "- Also note that this is fine-tune training. Which means we will re-tune the pre-trained weights.\n",
    "- **WARNING: Better if you have a GPU installed**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f2b21b-8335-490c-b818-cfa13d746c83",
   "metadata": {},
   "source": [
    "# Importing Packages and Setting of CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "386b19bf-8e20-47fc-a26f-012a14177688",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T09:41:52.058394Z",
     "iopub.status.busy": "2025-05-22T09:41:52.057834Z",
     "iopub.status.idle": "2025-05-22T09:41:52.065535Z",
     "shell.execute_reply": "2025-05-22T09:41:52.064665Z",
     "shell.execute_reply.started": "2025-05-22T09:41:52.058366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "NVIDIA GeForce RTX 2080 Ti\n",
      "NVIDIA GeForce RTX 2080 Ti\n",
      "Main Compute: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# This is to manually control which GPUs to use\n",
    "# In the laboratory we have a server with 4 GPUs\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3\"\n",
    "\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.device_count())  # Should output 2\n",
    "print(torch.cuda.get_device_name(0))  # Should correspond to GPU 2\n",
    "print(torch.cuda.get_device_name(1))  # Should correspond to GPU 3\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Main Compute: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a89be22-7b96-406a-8fdd-1a087c7ec947",
   "metadata": {},
   "source": [
    "# Downloading and Preparing CIFAR10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e6359fe-2640-4f84-afcf-1822bcf647a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T09:41:57.084543Z",
     "iopub.status.busy": "2025-05-22T09:41:57.084034Z",
     "iopub.status.idle": "2025-05-22T09:41:58.894054Z",
     "shell.execute_reply": "2025-05-22T09:41:58.891377Z",
     "shell.execute_reply.started": "2025-05-22T09:41:57.084492Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet standards\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                             download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                            download=True, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64,\n",
    "                                           shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64,\n",
    "                                          shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3cd90d-d120-4730-a04a-70515e2caf41",
   "metadata": {},
   "source": [
    "# Load and Modify VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aed75531-4209-4cee-afa4-103c2145de88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T09:42:25.510023Z",
     "iopub.status.busy": "2025-05-22T09:42:25.509344Z",
     "iopub.status.idle": "2025-05-22T09:42:27.111414Z",
     "shell.execute_reply": "2025-05-22T09:42:27.110618Z",
     "shell.execute_reply.started": "2025-05-22T09:42:25.509976Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/micas/rantonio/anaconda3/envs/tensorx/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/users/micas/rantonio/anaconda3/envs/tensorx/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): ReLU(inplace=True)\n",
       "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): ReLU(inplace=True)\n",
       "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (27): ReLU(inplace=True)\n",
       "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pretrained VGG16 model\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "# Freeze feature parameters\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the classifier\n",
    "model.classifier[6] = nn.Linear(4096, 10)\n",
    "\n",
    "# Move model to the appropriate device\n",
    "# Utilizes multiple GPUs\n",
    "model = torch.nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e422364d-512a-437e-84b8-5a0fbed9290b",
   "metadata": {},
   "source": [
    "# Define Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1657e9d0-2253-48f4-b809-0269c091f8ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T09:44:21.008798Z",
     "iopub.status.busy": "2025-05-22T09:44:21.008324Z",
     "iopub.status.idle": "2025-05-22T09:44:21.015247Z",
     "shell.execute_reply": "2025-05-22T09:44:21.014361Z",
     "shell.execute_reply.started": "2025-05-22T09:44:21.008771Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.module.classifier.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882c79dc-29ee-43de-8293-64327575be76",
   "metadata": {},
   "source": [
    "# Retrain the Model\n",
    "- Note that we can increase epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "709a8835-7184-481c-8c30-83598adc3ba2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T09:44:23.696988Z",
     "iopub.status.busy": "2025-05-22T09:44:23.696504Z",
     "iopub.status.idle": "2025-05-22T10:13:12.152296Z",
     "shell.execute_reply": "2025-05-22T10:13:12.151251Z",
     "shell.execute_reply.started": "2025-05-22T09:44:23.696959Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [02:53<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.7115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [02:51<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 0.5214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [02:52<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 0.4368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [02:52<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 0.4132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [02:53<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 0.3402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [02:53<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 0.3196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [02:52<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 0.3091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [02:52<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Loss: 0.2883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [02:53<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 0.2631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 782/782 [02:52<00:00,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.2462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7de13b1-f222-46b1-88c0-1756e0a62061",
   "metadata": {},
   "source": [
    "# Evaulating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2611b96-ff50-4567-bec8-f3be699fcbc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T10:13:56.181954Z",
     "iopub.status.busy": "2025-05-22T10:13:56.181443Z",
     "iopub.status.idle": "2025-05-22T10:14:20.036329Z",
     "shell.execute_reply": "2025-05-22T10:14:20.035422Z",
     "shell.execute_reply.started": "2025-05-22T10:13:56.181915Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:23<00:00,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on CIFAR-10 test images: 87.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy on CIFAR-10 test images: {100 * correct / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026f73ec-8b15-44ef-8942-d9273267759e",
   "metadata": {},
   "source": [
    "# Saving the Model\n",
    "- Note, the model is quite large and therefore needs to be saved somewhere separately\n",
    "- For this case it's around 500 MB large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "669897bc-d2f1-4503-8bbd-be25ba1d3285",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T10:17:33.059050Z",
     "iopub.status.busy": "2025-05-22T10:17:33.058413Z",
     "iopub.status.idle": "2025-05-22T10:17:39.242624Z",
     "shell.execute_reply": "2025-05-22T10:17:39.241097Z",
     "shell.execute_reply.started": "2025-05-22T10:17:33.059019Z"
    }
   },
   "outputs": [],
   "source": [
    "# If using DataParallel, access the underlying model\n",
    "torch.save(model.module.state_dict(), './pretrained_models/vgg16_train_finetune_cifar10.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b71660-f121-4b0c-acf4-e552f131ed42",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "- Fine-tuning the parameters allows us to achieve around 87.22% from 11.2%\n",
    "- Re-training helps a lot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3806f5-19f5-4764-8612-1006370e1f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
