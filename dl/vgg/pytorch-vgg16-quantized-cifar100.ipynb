{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "896b28dc-26e1-4bc0-939a-62b667e73d36",
   "metadata": {},
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12c4cecd-46d6-41c4-ae73-2509533af6f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T06:02:00.358149Z",
     "iopub.status.busy": "2025-05-28T06:02:00.357821Z",
     "iopub.status.idle": "2025-05-28T06:02:05.078744Z",
     "shell.execute_reply": "2025-05-28T06:02:05.077838Z",
     "shell.execute_reply.started": "2025-05-28T06:02:00.358118Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vgg16\n",
    "from torch.quantization import QuantStub, DeQuantStub\n",
    "import torch.quantization\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4f8810-b438-4128-acfb-73c64d416a15",
   "metadata": {},
   "source": [
    "# Downloading Data\n",
    "- Note that we apply a transform to the original CIFAR-100 data set $(3,32,32) \\rightarrow (3,224,224)$ where we have (channels, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "965c10b8-d1f3-41b2-89d5-6fbd905c27c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T06:02:05.080130Z",
     "iopub.status.busy": "2025-05-28T06:02:05.079670Z",
     "iopub.status.idle": "2025-05-28T06:02:06.986124Z",
     "shell.execute_reply": "2025-05-28T06:02:06.985348Z",
     "shell.execute_reply.started": "2025-05-28T06:02:05.080100Z"
    }
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5071, 0.4865, 0.4409],\n",
    "                         std=[0.2673, 0.2564, 0.2762])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5071, 0.4865, 0.4409],\n",
    "                         std=[0.2673, 0.2564, 0.2762])\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                         download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
    "                                          shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                        download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
    "                                         shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d613d8d9-71ce-409a-be95-6686d4bfb264",
   "metadata": {},
   "source": [
    "# Making the Model\n",
    "- It is important to note that we have to insert the `QuantStub` and `DeQuantStub` functions to tell the tool where to apply quantization for later\n",
    "- Also, in here we pull in the original `vgg16` model and we need to replace the final cassification layer to have 100 outputs instead of 1,000 because the former was due to CIFAR-100 having 100 classes only and the latter was because VGG16 was originally trained for ImageNet.\n",
    "- Then, there is a `fuse_model` function that fuses the convolution and ReLU together to have one ConvRelu operation. But particularly what this does is to have 1 quantization point (scale + zero point) for the combination of conv and relu all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24d3eeb8-caba-4e9e-9163-c3314fd3e11f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T06:02:06.987327Z",
     "iopub.status.busy": "2025-05-28T06:02:06.986995Z",
     "iopub.status.idle": "2025-05-28T06:02:06.996283Z",
     "shell.execute_reply": "2025-05-28T06:02:06.995613Z",
     "shell.execute_reply.started": "2025-05-28T06:02:06.987298Z"
    }
   },
   "outputs": [],
   "source": [
    "class QuantizableVGG16(nn.Module):\n",
    "    def __init__(self, num_classes=100):\n",
    "        super(QuantizableVGG16, self).__init__()\n",
    "        # LOOK! These are important to be defined\n",
    "        self.quant = QuantStub()\n",
    "        self.dequant = DeQuantStub()\n",
    "        # Use pretrained VGG16's features\n",
    "        self.features = vgg16(pretrained=True).features\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    # Observe how the quant and dequant are called\n",
    "    # You quantize the inputs then at the end\n",
    "    # They are dequantized\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "    def fuse_model(self):\n",
    "        # Fuse Conv + ReLU in VGG16 features\n",
    "        for idx in range(len(self.features)):\n",
    "            if isinstance(self.features[idx], nn.Conv2d):\n",
    "                next_idx = idx + 1\n",
    "                if next_idx < len(self.features) and isinstance(self.features[next_idx], nn.ReLU):\n",
    "                    torch.quantization.fuse_modules(self.features, [str(idx), str(next_idx)], inplace=True)\n",
    "\n",
    "        # Fuse classifier layers: Linear + ReLU\n",
    "        for idx in [0, 3]:  # indices of Linear layers followed by ReLU\n",
    "            torch.quantization.fuse_modules(self.classifier, [str(idx), str(idx + 1)], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239a47fa-343c-4267-b0a8-272cbde9a54e",
   "metadata": {},
   "source": [
    "# Model Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04515268-95e8-40ac-bb90-820719da97c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T06:02:06.997352Z",
     "iopub.status.busy": "2025-05-28T06:02:06.997042Z",
     "iopub.status.idle": "2025-05-28T06:02:10.131684Z",
     "shell.execute_reply": "2025-05-28T06:02:10.130658Z",
     "shell.execute_reply.started": "2025-05-28T06:02:06.997325Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/micas/rantonio/anaconda3/envs/torchx/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/users/micas/rantonio/anaconda3/envs/torchx/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "QuantizableVGG16                         [1, 100]                  --\n",
       "├─QuantStub: 1-1                         [1, 3, 224, 224]          --\n",
       "├─Sequential: 1-2                        [1, 512, 7, 7]            --\n",
       "│    └─Conv2d: 2-1                       [1, 64, 224, 224]         1,792\n",
       "│    └─ReLU: 2-2                         [1, 64, 224, 224]         --\n",
       "│    └─Conv2d: 2-3                       [1, 64, 224, 224]         36,928\n",
       "│    └─ReLU: 2-4                         [1, 64, 224, 224]         --\n",
       "│    └─MaxPool2d: 2-5                    [1, 64, 112, 112]         --\n",
       "│    └─Conv2d: 2-6                       [1, 128, 112, 112]        73,856\n",
       "│    └─ReLU: 2-7                         [1, 128, 112, 112]        --\n",
       "│    └─Conv2d: 2-8                       [1, 128, 112, 112]        147,584\n",
       "│    └─ReLU: 2-9                         [1, 128, 112, 112]        --\n",
       "│    └─MaxPool2d: 2-10                   [1, 128, 56, 56]          --\n",
       "│    └─Conv2d: 2-11                      [1, 256, 56, 56]          295,168\n",
       "│    └─ReLU: 2-12                        [1, 256, 56, 56]          --\n",
       "│    └─Conv2d: 2-13                      [1, 256, 56, 56]          590,080\n",
       "│    └─ReLU: 2-14                        [1, 256, 56, 56]          --\n",
       "│    └─Conv2d: 2-15                      [1, 256, 56, 56]          590,080\n",
       "│    └─ReLU: 2-16                        [1, 256, 56, 56]          --\n",
       "│    └─MaxPool2d: 2-17                   [1, 256, 28, 28]          --\n",
       "│    └─Conv2d: 2-18                      [1, 512, 28, 28]          1,180,160\n",
       "│    └─ReLU: 2-19                        [1, 512, 28, 28]          --\n",
       "│    └─Conv2d: 2-20                      [1, 512, 28, 28]          2,359,808\n",
       "│    └─ReLU: 2-21                        [1, 512, 28, 28]          --\n",
       "│    └─Conv2d: 2-22                      [1, 512, 28, 28]          2,359,808\n",
       "│    └─ReLU: 2-23                        [1, 512, 28, 28]          --\n",
       "│    └─MaxPool2d: 2-24                   [1, 512, 14, 14]          --\n",
       "│    └─Conv2d: 2-25                      [1, 512, 14, 14]          2,359,808\n",
       "│    └─ReLU: 2-26                        [1, 512, 14, 14]          --\n",
       "│    └─Conv2d: 2-27                      [1, 512, 14, 14]          2,359,808\n",
       "│    └─ReLU: 2-28                        [1, 512, 14, 14]          --\n",
       "│    └─Conv2d: 2-29                      [1, 512, 14, 14]          2,359,808\n",
       "│    └─ReLU: 2-30                        [1, 512, 14, 14]          --\n",
       "│    └─MaxPool2d: 2-31                   [1, 512, 7, 7]            --\n",
       "├─AdaptiveAvgPool2d: 1-3                 [1, 512, 7, 7]            --\n",
       "├─Sequential: 1-4                        [1, 100]                  --\n",
       "│    └─Linear: 2-32                      [1, 4096]                 102,764,544\n",
       "│    └─ReLU: 2-33                        [1, 4096]                 --\n",
       "│    └─Dropout: 2-34                     [1, 4096]                 --\n",
       "│    └─Linear: 2-35                      [1, 4096]                 16,781,312\n",
       "│    └─ReLU: 2-36                        [1, 4096]                 --\n",
       "│    └─Dropout: 2-37                     [1, 4096]                 --\n",
       "│    └─Linear: 2-38                      [1, 100]                  409,700\n",
       "├─DeQuantStub: 1-5                       [1, 100]                  --\n",
       "==========================================================================================\n",
       "Total params: 134,670,244\n",
       "Trainable params: 134,670,244\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 15.48\n",
       "==========================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 108.45\n",
       "Params size (MB): 538.68\n",
       "Estimated Total Size (MB): 647.73\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "model = QuantizableVGG16()\n",
    "summary(model, input_size=(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e476b17a-a1ab-4d7d-bf1d-3fd1c30ab74f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T06:02:10.133840Z",
     "iopub.status.busy": "2025-05-28T06:02:10.133349Z",
     "iopub.status.idle": "2025-05-28T06:02:11.734607Z",
     "shell.execute_reply": "2025-05-28T06:02:11.733495Z",
     "shell.execute_reply.started": "2025-05-28T06:02:10.133804Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/micas/rantonio/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuantizableVGG16(\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "      fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "    )\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       "  (features): Sequential(\n",
       "    (0): ConvReLU2d(\n",
       "      3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "        (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "      )\n",
       "      (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "        (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (1): Identity()\n",
       "    (2): ConvReLU2d(\n",
       "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "        (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "      )\n",
       "      (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "        (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (3): Identity()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): ConvReLU2d(\n",
       "      64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "        (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "      )\n",
       "      (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "        (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (6): Identity()\n",
       "    (7): ConvReLU2d(\n",
       "      128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "        (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "      )\n",
       "      (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "        (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (8): Identity()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): ConvReLU2d(\n",
       "      128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "        (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "      )\n",
       "      (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "        (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (11): Identity()\n",
       "    (12): ConvReLU2d(\n",
       "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "        (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "      )\n",
       "      (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "        (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (13): Identity()\n",
       "    (14): ConvReLU2d(\n",
       "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "        (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "      )\n",
       "      (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "        (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (15): Identity()\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): ConvReLU2d(\n",
       "      256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "        (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "      )\n",
       "      (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "        (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (18): Identity()\n",
       "    (19): ConvReLU2d(\n",
       "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "        (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "      )\n",
       "      (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "        (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (20): Identity()\n",
       "    (21): ConvReLU2d(\n",
       "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "        (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "      )\n",
       "      (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "        (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (22): Identity()\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): ConvReLU2d(\n",
       "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "        (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "      )\n",
       "      (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "        (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (25): Identity()\n",
       "    (26): ConvReLU2d(\n",
       "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "        (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "      )\n",
       "      (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "        (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (27): Identity()\n",
       "    (28): ConvReLU2d(\n",
       "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "      (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "        (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "      )\n",
       "      (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "        (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (29): Identity()\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): LinearReLU(\n",
       "      in_features=25088, out_features=4096, bias=True\n",
       "      (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "        (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "      )\n",
       "      (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "        (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (1): Identity()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): LinearReLU(\n",
       "      in_features=4096, out_features=4096, bias=True\n",
       "      (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "        (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "      )\n",
       "      (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "        (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (4): Identity()\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(\n",
       "      in_features=4096, out_features=100, bias=True\n",
       "      (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "        (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "      )\n",
       "      (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "        (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go into training mode\n",
    "model.train()\n",
    "\n",
    "# Fuse Conv, BN, and ReLU layers\n",
    "model.fuse_model()\n",
    "\n",
    "# Set quantization configuration\n",
    "model.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n",
    "\n",
    "# Prepare for QAT\n",
    "torch.quantization.prepare_qat(model, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0741b8b5-86f3-4584-bb32-000531337c6a",
   "metadata": {},
   "source": [
    "# Set to use GPUs in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49088998-2742-4417-a475-d78dfec05b84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T06:02:11.737843Z",
     "iopub.status.busy": "2025-05-28T06:02:11.737417Z",
     "iopub.status.idle": "2025-05-28T06:02:11.798082Z",
     "shell.execute_reply": "2025-05-28T06:02:11.797347Z",
     "shell.execute_reply.started": "2025-05-28T06:02:11.737804Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): QuantizableVGG16(\n",
       "    (quant): QuantStub(\n",
       "      (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "        fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "        (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "      )\n",
       "    )\n",
       "    (dequant): DeQuantStub()\n",
       "    (features): Sequential(\n",
       "      (0): ConvReLU2d(\n",
       "        3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "      (1): Identity()\n",
       "      (2): ConvReLU2d(\n",
       "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "      (3): Identity()\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): ConvReLU2d(\n",
       "        64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "      (6): Identity()\n",
       "      (7): ConvReLU2d(\n",
       "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "      (8): Identity()\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): ConvReLU2d(\n",
       "        128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "      (11): Identity()\n",
       "      (12): ConvReLU2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "      (13): Identity()\n",
       "      (14): ConvReLU2d(\n",
       "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "      (15): Identity()\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (17): ConvReLU2d(\n",
       "        256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "      (18): Identity()\n",
       "      (19): ConvReLU2d(\n",
       "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "      (20): Identity()\n",
       "      (21): ConvReLU2d(\n",
       "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "      (22): Identity()\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): ConvReLU2d(\n",
       "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "      (25): Identity()\n",
       "      (26): ConvReLU2d(\n",
       "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "      (27): Identity()\n",
       "      (28): ConvReLU2d(\n",
       "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "      (29): Identity()\n",
       "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Sequential(\n",
       "      (0): LinearReLU(\n",
       "        in_features=25088, out_features=4096, bias=True\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "      (1): Identity()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): LinearReLU(\n",
       "        in_features=4096, out_features=4096, bias=True\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "      (4): Identity()\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(\n",
       "        in_features=4096, out_features=100, bias=True\n",
       "        (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_channel_symmetric, reduce_range=False\n",
       "          (activation_post_process): MovingAveragePerChannelMinMaxObserver(min_val=tensor([], device='cuda:0'), max_val=tensor([], device='cuda:0'))\n",
       "        )\n",
       "        (activation_post_process): FusedMovingAvgObsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0'), observer_enabled=tensor([1], device='cuda:0'), scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=True\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a85c5f-6d78-4292-a9f9-3853843a22e5",
   "metadata": {},
   "source": [
    "# Set training parameters and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca146c74-e98f-4241-8c9c-1b436e9bcd31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T06:02:11.799148Z",
     "iopub.status.busy": "2025-05-28T06:02:11.798872Z",
     "iopub.status.idle": "2025-05-28T06:16:33.187229Z",
     "shell.execute_reply": "2025-05-28T06:16:33.186159Z",
     "shell.execute_reply.started": "2025-05-28T06:02:11.799120Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [02:52<00:00,  2.26it/s, loss=2.47]\n",
      "Epoch 2/5: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [02:51<00:00,  2.28it/s, loss=1.36]\n",
      "Epoch 3/5: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [02:51<00:00,  2.27it/s, loss=1.03]\n",
      "Epoch 4/5: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [02:52<00:00,  2.26it/s, loss=0.844]\n",
      "Epoch 5/5: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [02:52<00:00,  2.27it/s, loss=0.697]\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    progress_bar = tqdm(trainloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    for inputs, labels in progress_bar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=running_loss / (progress_bar.n + 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a243fc-304f-4f33-a47d-d0cd00a3fa50",
   "metadata": {},
   "source": [
    "# Evaluate Model Before Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5bd35e5-6dd9-4f09-8f3b-f067eecde4b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T06:16:33.188838Z",
     "iopub.status.busy": "2025-05-28T06:16:33.188411Z",
     "iopub.status.idle": "2025-05-28T06:16:50.912312Z",
     "shell.execute_reply": "2025-05-28T06:16:50.911350Z",
     "shell.execute_reply.started": "2025-05-28T06:16:33.188800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:17<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the quantized model: 69.48%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "69.48"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def orig_evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    model.to('cuda')\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    print(f\"Accuracy of the quantized model: {acc:.2f}%\")\n",
    "    return acc\n",
    "\n",
    "\n",
    "orig_evaluate(model, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f635982-a86e-4b84-be7d-8c36b2d425fe",
   "metadata": {},
   "source": [
    "# Convert Model to be Quantized\n",
    "- This step makes the model with int8 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac9993d7-2d3e-4a83-8979-75d66a90194c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T06:16:50.913833Z",
     "iopub.status.busy": "2025-05-28T06:16:50.913457Z",
     "iopub.status.idle": "2025-05-28T06:16:54.325836Z",
     "shell.execute_reply": "2025-05-28T06:16:54.324935Z",
     "shell.execute_reply.started": "2025-05-28T06:16:50.913799Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.cpu()\n",
    "quantized_model = torch.quantization.convert(model, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced26e2e-7a44-4e09-9462-7477d7cb6c95",
   "metadata": {},
   "source": [
    "# Save quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e72a4ad5-22f4-4ff7-bfbf-91351ab47508",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T06:16:54.326888Z",
     "iopub.status.busy": "2025-05-28T06:16:54.326597Z",
     "iopub.status.idle": "2025-05-28T06:16:56.935190Z",
     "shell.execute_reply": "2025-05-28T06:16:56.934163Z",
     "shell.execute_reply.started": "2025-05-28T06:16:54.326856Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(quantized_model.state_dict(), 'quantized_vgg16_cifar100.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22058131-488f-4449-8360-f1abc690b1b4",
   "metadata": {},
   "source": [
    "# Setting Quantized Model to CPU\n",
    "- This is mandatory as CPU can do the int8 operations but GPUs can only do FP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75aa470a-8743-4ef0-b267-d42a8ffd2645",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T06:16:56.936866Z",
     "iopub.status.busy": "2025-05-28T06:16:56.936586Z",
     "iopub.status.idle": "2025-05-28T06:16:57.822685Z",
     "shell.execute_reply": "2025-05-28T06:16:57.821906Z",
     "shell.execute_reply.started": "2025-05-28T06:16:56.936837Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantizableVGG16(\n",
       "  (quant): Quantize(scale=tensor([0.0309]), zero_point=tensor([61]), dtype=torch.quint8)\n",
       "  (dequant): DeQuantize()\n",
       "  (features): Sequential(\n",
       "    (0): QuantizedConvReLU2d(3, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.0859326645731926, zero_point=0, padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.14404772222042084, zero_point=0, padding=(1, 1))\n",
       "    (3): Identity()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): QuantizedConvReLU2d(64, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.23559726774692535, zero_point=0, padding=(1, 1))\n",
       "    (6): Identity()\n",
       "    (7): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.3782609701156616, zero_point=0, padding=(1, 1))\n",
       "    (8): Identity()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): QuantizedConvReLU2d(128, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.40806472301483154, zero_point=0, padding=(1, 1))\n",
       "    (11): Identity()\n",
       "    (12): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.48023858666419983, zero_point=0, padding=(1, 1))\n",
       "    (13): Identity()\n",
       "    (14): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.6935874819755554, zero_point=0, padding=(1, 1))\n",
       "    (15): Identity()\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): QuantizedConvReLU2d(256, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.6415135264396667, zero_point=0, padding=(1, 1))\n",
       "    (18): Identity()\n",
       "    (19): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.5167954564094543, zero_point=0, padding=(1, 1))\n",
       "    (20): Identity()\n",
       "    (21): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.4827077090740204, zero_point=0, padding=(1, 1))\n",
       "    (22): Identity()\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.39359724521636963, zero_point=0, padding=(1, 1))\n",
       "    (25): Identity()\n",
       "    (26): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.3256794214248657, zero_point=0, padding=(1, 1))\n",
       "    (27): Identity()\n",
       "    (28): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.3113672435283661, zero_point=0, padding=(1, 1))\n",
       "    (29): Identity()\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): QuantizedLinearReLU(in_features=25088, out_features=4096, scale=0.0880572646856308, zero_point=0, qscheme=torch.per_channel_affine)\n",
       "    (1): Identity()\n",
       "    (2): QuantizedDropout(p=0.5, inplace=False)\n",
       "    (3): QuantizedLinearReLU(in_features=4096, out_features=4096, scale=0.04885133355855942, zero_point=0, qscheme=torch.per_channel_affine)\n",
       "    (4): Identity()\n",
       "    (5): QuantizedDropout(p=0.5, inplace=False)\n",
       "    (6): QuantizedLinear(in_features=4096, out_features=100, scale=0.3745822608470917, zero_point=38, qscheme=torch.per_channel_affine)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure model is quantized and on CPU\n",
    "quantized_model = quantized_model.module  # unwrap from DataParallel\n",
    "quantized_model.eval()\n",
    "quantized_model.to('cpu')  # <--- this fixes the RuntimeError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18be92d6-022b-41fe-8605-01bcc78be405",
   "metadata": {},
   "source": [
    "# Evaluate the Quantized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbb794d3-2215-4644-9021-21b5b84c10e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T06:16:57.824051Z",
     "iopub.status.busy": "2025-05-28T06:16:57.823777Z",
     "iopub.status.idle": "2025-05-28T06:24:12.349361Z",
     "shell.execute_reply": "2025-05-28T06:24:12.348456Z",
     "shell.execute_reply.started": "2025-05-28T06:16:57.824023Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [07:14<00:00,  5.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the quantized model: 69.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "69.33"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    model.to('cpu')  # ensure model is on CPU\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            inputs = inputs.cpu()\n",
    "            labels = labels.cpu()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    print(f\"Accuracy of the quantized model: {acc:.2f}%\")\n",
    "    return acc\n",
    "\n",
    "\n",
    "evaluate(quantized_model, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353fbde2-8a89-4556-ac38-88ac8acd6f40",
   "metadata": {},
   "source": [
    "# Saving ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd0a3b03-d95a-4ae0-a12d-2dfc58a6e466",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T06:24:12.350904Z",
     "iopub.status.busy": "2025-05-28T06:24:12.350494Z",
     "iopub.status.idle": "2025-05-28T06:24:12.356816Z",
     "shell.execute_reply": "2025-05-28T06:24:12.356097Z",
     "shell.execute_reply.started": "2025-05-28T06:24:12.350870Z"
    }
   },
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1, 3, 224, 224)  # ONNX needs a batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64edad7d-a3de-4811-94c0-d94766e3da9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T06:24:12.358030Z",
     "iopub.status.busy": "2025-05-28T06:24:12.357721Z",
     "iopub.status.idle": "2025-05-28T06:24:17.217932Z",
     "shell.execute_reply": "2025-05-28T06:24:17.217153Z",
     "shell.execute_reply.started": "2025-05-28T06:24:12.358002Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.onnx.export(\n",
    "    quantized_model,\n",
    "    dummy_input,\n",
    "    \"quantized_vgg16.onnx\",\n",
    "    export_params=True,\n",
    "    opset_version=13,  # Use 13+ for better quant support\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6638e8-0978-475a-82fc-e937ec281543",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
