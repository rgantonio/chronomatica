{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77fefd10",
   "metadata": {},
   "source": [
    "# Basic Convolution\n",
    "\n",
    "Convolution is a means to compress information or data across a window of data. It can be in 1D or 2D. Here we demonstrate through simple code how the convolution works and how we would code it in vanilla element-wise operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86ead330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f945b90",
   "metadata": {},
   "source": [
    "## Mathematics\n",
    "\n",
    "For 1D convolution:\n",
    "\n",
    "$$ y[n] = \\sum_{k=0}^{M-1} h[k] \\cdot x[n-k]$$\n",
    "\n",
    "Where $M$ shows that the $h$ filter is bounded. \n",
    "\n",
    "\n",
    "For 2D convolution:\n",
    "\n",
    "$$ Y[i,j] = \\sum_{m=0}^{K-1}\\sum_{n=0}^{K-1} H[m,n] \\cdot X[i-m,j-n]$$\n",
    "\n",
    "$X$ or $x$ are padded when they are out of bounds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158572e3",
   "metadata": {},
   "source": [
    "## Code for Simple Convolution\n",
    "\n",
    "### For 1D Convolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "903f42d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolution output: tensor([ 2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2., -9.])\n"
     ]
    }
   ],
   "source": [
    "# Setup for simple 1D convolution\n",
    "\n",
    "# Simple vector for 1D convolution\n",
    "# Padded on 2 ends\n",
    "vector_x = torch.tensor([0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 0.0])\n",
    "\n",
    "# Simple 1x3 kernel\n",
    "kernel = torch.tensor([-1.0, 0.0, 1.0])\n",
    "\n",
    "# Simple convolution function\n",
    "def conv1d(x, k):\n",
    "    # Get the length of the input and kernel\n",
    "    x_len = len(x)\n",
    "    k_len = len(k)\n",
    "\n",
    "    # Calculate the length of the output\n",
    "    out_len = x_len - k_len + 1\n",
    "\n",
    "    # Initialize the output tensor\n",
    "    out = torch.zeros(out_len)\n",
    "\n",
    "    # Perform the convolution operation\n",
    "    for i in range(out_len):\n",
    "        for j in range(k_len):\n",
    "            out[i] += x[i + j] * k[j]\n",
    "    return out\n",
    "\n",
    "# Perform the convolution\n",
    "out = conv1d(vector_x, kernel)\n",
    "print(\"Convolution output:\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51ba32fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 1D output: tensor([[[ 2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2., -9.]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "PyTorch 1D size: torch.Size([1, 1, 10])\n"
     ]
    }
   ],
   "source": [
    "# 1D Convolution using PyTorch\n",
    "vector_x = torch.tensor([[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 0.0]])\n",
    "vector_x = vector_x.unsqueeze(0) # Add batch and channel dimensions\n",
    "\n",
    "# Reshape kernel to match PyTorch's expected input\n",
    "kernel = torch.tensor([[[-1.0, 0.0, 1.0]]])  # (out_channels=1, in_channels=1, kernel_size=3)\n",
    "\n",
    "conv1d = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=3, bias=False)\n",
    "conv1d.weight.data = kernel\n",
    "pytorch_1d = conv1d(vector_x)\n",
    "\n",
    "print(\"PyTorch 1D output:\", pytorch_1d)\n",
    "print(\"PyTorch 1D size:\", pytorch_1d.size())\n",
    "\n",
    "# Size is batch x output_channels x length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d95df94",
   "metadata": {},
   "source": [
    "### For 2D Convolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd6d539d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D Convolution Output:\n",
      " tensor([[  9.,   6.,  -9.],\n",
      "        [ 20.,   8., -20.],\n",
      "        [ 21.,   6., -21.]])\n"
     ]
    }
   ],
   "source": [
    "# Simple 2D matrix with zero-padding already applied\n",
    "matrix_x = torch.tensor([\n",
    "    [0.0,  0.0,  0.0,  0.0, 0.0],\n",
    "    [0.0,  1.0,  2.0,  3.0, 0.0],\n",
    "    [0.0,  4.0,  5.0,  6.0, 0.0],\n",
    "    [0.0,  7.0,  8.0,  9.0, 0.0],\n",
    "    [0.0,  0.0,  0.0,  0.0, 0.0]\n",
    "])\n",
    "\n",
    "# Simple 3x3 kernel (e.g., Sobel-like edge detector)\n",
    "kernel_2d = torch.tensor([\n",
    "    [-1.0, 0.0, 1.0],\n",
    "    [-2.0, 0.0, 2.0],\n",
    "    [-1.0, 0.0, 1.0]\n",
    "])\n",
    "\n",
    "# 2D convolution function (no batch or channels)\n",
    "def conv2d(x, k):\n",
    "    IX, IY = x.shape\n",
    "    KX, KY = k.shape\n",
    "    OX = IX - KX + 1\n",
    "    OY = IY - KY + 1\n",
    "\n",
    "    out = torch.zeros((OX, OY))\n",
    "\n",
    "    for ox in range(OX):\n",
    "        for oy in range(OY):\n",
    "            for kx in range(KX):\n",
    "                for ky in range(KY):\n",
    "                    out[ox, oy] += x[ox + kx, oy + ky] * k[kx, ky]\n",
    "    return out\n",
    "\n",
    "# Perform 2D convolution\n",
    "output_2d = conv2d(matrix_x, kernel_2d)\n",
    "\n",
    "print(\"2D Convolution Output:\\n\", output_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "651d024f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 2D output:\n",
      " tensor([[[[  9.,   6.,  -9.],\n",
      "          [ 20.,   8., -20.],\n",
      "          [ 21.,   6., -21.]]]], grad_fn=<ConvolutionBackward0>)\n",
      "PyTorch 2D size: torch.Size([1, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Input 2D matrix with padding already applied\n",
    "matrix_x = torch.tensor([\n",
    "    [0.0,  0.0,  0.0,  0.0, 0.0],\n",
    "    [0.0,  1.0,  2.0,  3.0, 0.0],\n",
    "    [0.0,  4.0,  5.0,  6.0, 0.0],\n",
    "    [0.0,  7.0,  8.0,  9.0, 0.0],\n",
    "    [0.0,  0.0,  0.0,  0.0, 0.0]\n",
    "])\n",
    "\n",
    "# Reshape input to match PyTorch's 2D conv format: (batch, channels, height, width)\n",
    "matrix_x = matrix_x.unsqueeze(0).unsqueeze(0)  # shape: (1, 1, 5, 5)\n",
    "\n",
    "# Define a 3x3 kernel, same as in the manual version\n",
    "kernel_2d = torch.tensor([[[[-1.0, 0.0, 1.0],\n",
    "                            [-2.0, 0.0, 2.0],\n",
    "                            [-1.0, 0.0, 1.0]]]])  # shape: (out_channels=1, in_channels=1, 3, 3)\n",
    "\n",
    "# Set up Conv2d layer\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, bias=False)\n",
    "conv2d.weight.data = kernel_2d  # manually set the weights\n",
    "\n",
    "# Perform the convolution\n",
    "pytorch_2d = conv2d(matrix_x)\n",
    "\n",
    "print(\"PyTorch 2D output:\\n\", pytorch_2d)\n",
    "print(\"PyTorch 2D size:\", pytorch_2d.size())  # should be (1, 1, H_out, W_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc9235b",
   "metadata": {},
   "source": [
    "## Code for Multiple Channel Convolution\n",
    "\n",
    "### For 1D with multiple input and output channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9a3d333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolution output shape: torch.Size([3, 10])\n",
      "Convolution output:\n",
      " tensor([[ 2.5000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,\n",
      "          3.0000, -8.5000],\n",
      "        [ 1.0000,  1.0000,  1.0000,  4.0000,  4.0000,  4.0000,  7.0000,  7.0000,\n",
      "          7.0000, 20.0000],\n",
      "        [ 1.0000,  2.0000,  4.0000,  5.0000,  5.0000,  7.0000,  8.0000,  8.0000,\n",
      "         10.0000, 10.0000]])\n"
     ]
    }
   ],
   "source": [
    "# === Inputs ===\n",
    "# Let's say we have 3 input channels (C_in=3), each of length 12\n",
    "vector_x = torch.tensor([\n",
    "    [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 0.0],   # Channel 1\n",
    "    [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,  1.0, 0.0],   # Channel 2\n",
    "    [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0,  0.0, 0.0]    # Channel 3\n",
    "])  # Shape: (in_channels=3, length=12)\n",
    "\n",
    "# === Kernel ===\n",
    "# We have 3 output channels. Each output channel has 3 input-channel filters.\n",
    "# So the full kernel shape is (out_channels=3, in_channels=3, kernel_size=3)\n",
    "kernel = torch.tensor([\n",
    "    [[-1.0,  0.0,  1.0],    [0.5,  0.0, -0.5],  [ 1.0,  1.0, 1.0]],    # Kernel for output channel 0\n",
    "    [[ 1.0,  1.0, -1.0],    [0.0,  1.0,  0.0],  [-1.0,  0.0, 1.0]],    # Kernel for output channel 1\n",
    "    [[ 0.0,  1.0,  0.0],    [1.0, -1.0,  1.0],  [ 0.0, -1.0, 0.0]]     # Kernel for output channel 2\n",
    "])  # Shape: (3, 3, 3)\n",
    "\n",
    "# === Convolution function with multi-input and multi-output ===\n",
    "def conv1d_multi(x, k):\n",
    "    in_channels, x_len = x.shape\n",
    "    out_channels, _, k_len = k.shape\n",
    "    out_len = x_len - k_len + 1\n",
    "    out = torch.zeros(out_channels, out_len)\n",
    "\n",
    "    for oc in range(out_channels):\n",
    "        for ox in range(out_len):\n",
    "            for ic in range(in_channels):\n",
    "                for kx in range(k_len):\n",
    "                    out[oc, ox] += x[ic, ox + kx] * k[oc, ic, kx]\n",
    "    return out\n",
    "\n",
    "# === Perform convolution ===\n",
    "out = conv1d_multi(vector_x, kernel)\n",
    "\n",
    "print(\"Convolution output shape:\", out.shape)  # Should be (3, output_len)\n",
    "print(\"Convolution output:\\n\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2b2abba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Convolution Output Shape: torch.Size([1, 3, 10])\n",
      "PyTorch Convolution Output:\n",
      " tensor([[ 2.5000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,\n",
      "          3.0000, -8.5000],\n",
      "        [ 1.0000,  1.0000,  1.0000,  4.0000,  4.0000,  4.0000,  7.0000,  7.0000,\n",
      "          7.0000, 20.0000],\n",
      "        [ 1.0000,  2.0000,  4.0000,  5.0000,  5.0000,  7.0000,  8.0000,  8.0000,\n",
      "         10.0000, 10.0000]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Input: 3 input channels, 1 batch ===\n",
    "# Shape: (batch_size=1, in_channels=3, length=12)\n",
    "vector_x = torch.tensor([[\n",
    "    [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 0.0],    # Channel 1\n",
    "    [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,  1.0, 0.0],    # Channel 2\n",
    "    [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0,  0.0, 0.0]     # Channel 3\n",
    "]])\n",
    "\n",
    "# === Kernel: 3 output channels, 3 input channels, kernel size 3 ===\n",
    "kernel = torch.tensor([\n",
    "    [[-1.0,  0.0,  1.0],   [0.5,  0.0, -0.5],  [ 1.0,  1.0, 1.0]],    # Kernel for output channel 0\n",
    "    [[ 1.0,  1.0, -1.0],   [0.0,  1.0,  0.0],  [-1.0,  0.0, 1.0]],    # Kernel for output channel 1\n",
    "    [[ 0.0,  1.0,  0.0],   [1.0, -1.0,  1.0],  [ 0.0, -1.0, 0.0]]     # Kernel for output channel 2\n",
    "])\n",
    "\n",
    "# === Create Conv1d layer ===\n",
    "conv1d = nn.Conv1d(in_channels=3, out_channels=3, kernel_size=3, bias=False)\n",
    "\n",
    "# Set weights manually\n",
    "with torch.no_grad():\n",
    "    conv1d.weight.copy_(kernel)\n",
    "\n",
    "# === Apply convolution ===\n",
    "output = conv1d(vector_x)\n",
    "\n",
    "print(\"PyTorch Convolution Output Shape:\", output.shape)  # (1, 3, 10)\n",
    "print(\"PyTorch Convolution Output:\\n\", output[0])  # Remove batch dimension for display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457b3cf1",
   "metadata": {},
   "source": [
    "### For 2D convolutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1f7e2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual Multi-Channel 2D Convolution Output:\n",
      " tensor([[[ 12.5000,   7.5000,  -8.5000],\n",
      "         [ 21.5000,  11.5000, -18.5000],\n",
      "         [ 21.5000,   7.5000, -17.5000]],\n",
      "\n",
      "        [[ -8.5000, -12.5000,  -9.5000],\n",
      "         [ -9.5000, -17.5000,  -9.5000],\n",
      "         [ 10.5000,  17.5000,  11.5000]]])\n",
      "Shape: torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# === Input tensor: (in_channels=3, H=5, W=5), already padded ===\n",
    "input_tensor = torch.stack([\n",
    "    torch.tensor([\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 1.0, 2.0, 3.0, 0.0],\n",
    "        [0.0, 4.0, 5.0, 6.0, 0.0],\n",
    "        [0.0, 7.0, 8.0, 9.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    ]),\n",
    "    torch.ones((5, 5)),               # 2nd channel: all 1s\n",
    "    torch.eye(5)                      # 3rd channel: identity matrix\n",
    "])  # Shape: (3, 5, 5)\n",
    "\n",
    "# === Kernel: (out_channels=2, in_channels=3, kernel_size=3x3)\n",
    "kernel = torch.tensor([\n",
    "    [  # Kernel for output channel 0\n",
    "        [[-1.0, 0.0, 1.0],\n",
    "         [-2.0, 0.0, 2.0],\n",
    "         [-1.0, 0.0, 1.0]],\n",
    "        [[0.0, 0.0, 0.0],\n",
    "         [0.5, 0.5, 0.5],\n",
    "         [0.0, 0.0, 0.0]],\n",
    "        [[1.0, 0.0, -1.0],\n",
    "         [0.0, 0.0,  0.0],\n",
    "         [-1.0, 0.0, 1.0]]\n",
    "    ],\n",
    "    [  # Kernel for output channel 1\n",
    "        [[1.0, 1.0, 1.0],\n",
    "         [0.0, 0.0, 0.0],\n",
    "         [-1.0, -1.0, -1.0]],\n",
    "        [[0.0, 0.5, 0.0],\n",
    "         [0.0, 0.5, 0.0],\n",
    "         [0.0, 0.5, 0.0]],\n",
    "        [[0.0, 0.0, 0.0],\n",
    "         [1.0, -1.0, 1.0],\n",
    "         [0.0, 0.0, 0.0]]\n",
    "    ]\n",
    "])  # Shape: (2, 3, 3, 3)\n",
    "\n",
    "def conv2d_multi(x, k):\n",
    "    in_channels, IX, IY = x.shape\n",
    "    out_channels, _, KX, KY = k.shape\n",
    "    OX, OY = IX - KX + 1, IY - KY + 1\n",
    "    out = torch.zeros((out_channels, OX, OY))\n",
    "\n",
    "    for oc in range(out_channels):\n",
    "        for ox in range(OX):\n",
    "            for oy in range(OY):\n",
    "                for ic in range(in_channels):\n",
    "                    for kx in range(KX):\n",
    "                        for ky in range(KY):\n",
    "                            out[oc, ox, oy] += x[ic, ox + kx, oy + ky] * k[oc, ic, kx, ky]\n",
    "    return out\n",
    "\n",
    "# Run convolution\n",
    "manual_output = conv2d_multi(input_tensor, kernel)\n",
    "\n",
    "print(\"Manual Multi-Channel 2D Convolution Output:\\n\", manual_output)\n",
    "print(\"Shape:\", manual_output.shape)  # Expected: (2, 3, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "890ccc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Conv2d Output:\n",
      " tensor([[[ 12.5000,   7.5000,  -8.5000],\n",
      "         [ 21.5000,  11.5000, -18.5000],\n",
      "         [ 21.5000,   7.5000, -17.5000]],\n",
      "\n",
      "        [[ -8.5000, -12.5000,  -9.5000],\n",
      "         [ -9.5000, -17.5000,  -9.5000],\n",
      "         [ 10.5000,  17.5000,  11.5000]]], grad_fn=<SelectBackward0>)\n",
      "Shape: torch.Size([1, 2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Reshape input to PyTorch format: (batch_size=1, in_channels=3, H=5, W=5)\n",
    "input_tensor_pt = input_tensor.unsqueeze(0)\n",
    "\n",
    "# Create Conv2d layer: 3 in channels → 2 out channels\n",
    "conv2d = nn.Conv2d(in_channels=3, out_channels=2, kernel_size=3, bias=False)\n",
    "\n",
    "# Set weights manually to match\n",
    "with torch.no_grad():\n",
    "    conv2d.weight.copy_(kernel)\n",
    "\n",
    "# Apply convolution\n",
    "pytorch_output = conv2d(input_tensor_pt)\n",
    "\n",
    "print(\"PyTorch Conv2d Output:\\n\", pytorch_output[0])  # remove batch dimension for display\n",
    "print(\"Shape:\", pytorch_output.shape)  # Expected: (1, 2, 3, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b611b4b",
   "metadata": {},
   "source": [
    "## Convolutions when batch size is 2\n",
    "\n",
    "### For 1D Convolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5616602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual Conv Output Shape: torch.Size([2, 3, 10])\n",
      "Manual Conv Output:\n",
      " tensor([[[ 2.5000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,\n",
      "           3.0000,  3.0000, -8.5000],\n",
      "         [ 1.0000,  1.0000,  1.0000,  4.0000,  4.0000,  4.0000,  7.0000,\n",
      "           7.0000,  7.0000, 20.0000],\n",
      "         [ 1.0000,  2.0000,  4.0000,  5.0000,  5.0000,  7.0000,  8.0000,\n",
      "           8.0000, 10.0000, 10.0000]],\n",
      "\n",
      "        [[ 9.0000, -1.0000,  0.0000, -1.0000,  0.0000, -1.0000,  0.0000,\n",
      "          -1.0000,  0.0000,  0.0000],\n",
      "         [ 2.0000, 10.0000,  9.0000,  8.0000,  7.0000,  6.0000,  5.0000,\n",
      "           4.0000,  3.0000,  1.0000],\n",
      "         [ 9.0000,  7.0000,  7.0000,  5.0000,  5.0000,  3.0000,  3.0000,\n",
      "           1.0000,  1.0000, -1.0000]]])\n"
     ]
    }
   ],
   "source": [
    "# === Manual Conv1D: With 2 samples in the batch ===\n",
    "\n",
    "# Shape: (batch_size=2, in_channels=3, length=12)\n",
    "vector_x = torch.tensor([\n",
    "    [  # Sample 1\n",
    "        [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 0.0],\n",
    "        [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,  1.0, 0.0],\n",
    "        [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0,  0.0, 0.0]\n",
    "    ],\n",
    "    [  # Sample 2\n",
    "        [ 0.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.0, 0.0],\n",
    "        [ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [ 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0]\n",
    "    ]   \n",
    "])\n",
    "\n",
    "# Kernel shape: (out_channels=3, in_channels=3, kernel_size=3)\n",
    "kernel = torch.tensor([\n",
    "    [[-1.0,  0.0,  1.0],   [0.5, 0.0, -0.5], [1.0, 1.0, 1.0]],\n",
    "    [[1.0,  1.0, -1.0],    [0.0, 1.0, 0.0],  [-1.0, 0.0, 1.0]],\n",
    "    [[0.0,  1.0,  0.0],    [1.0, -1.0, 1.0], [0.0, -1.0, 0.0]]\n",
    "])\n",
    "\n",
    "# Manual multi-batch convolution\n",
    "def conv1d_batch(x, k):\n",
    "    batch_size, in_channels, x_len = x.shape\n",
    "    out_channels, _, k_len = k.shape\n",
    "    out_len = x_len - k_len + 1\n",
    "    out = torch.zeros((batch_size, out_channels, out_len))\n",
    "\n",
    "    for b in range(batch_size):\n",
    "        for oc in range(out_channels):\n",
    "            for i in range(out_len):\n",
    "                for ic in range(in_channels):\n",
    "                    for j in range(k_len):\n",
    "                        out[b, oc, i] += x[b, ic, i + j] * k[oc, ic, j]\n",
    "    return out\n",
    "\n",
    "# Run it\n",
    "out_manual = conv1d_batch(vector_x, kernel)\n",
    "\n",
    "print(\"Manual Conv Output Shape:\", out_manual.shape)  # (2, 3, 10)\n",
    "print(\"Manual Conv Output:\\n\", out_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fe18619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Conv Output Shape: torch.Size([2, 3, 10])\n",
      "PyTorch Conv Output:\n",
      " tensor([[[ 2.5000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,\n",
      "           3.0000,  3.0000, -7.5000],\n",
      "         [ 1.0000,  1.0000,  1.0000,  4.0000,  4.0000,  4.0000,  7.0000,\n",
      "           7.0000,  7.0000, 21.0000],\n",
      "         [ 1.0000,  2.0000,  4.0000,  5.0000,  5.0000,  7.0000,  8.0000,\n",
      "           8.0000, 10.0000, 10.0000]],\n",
      "\n",
      "        [[ 9.0000, -1.0000,  0.0000, -1.0000,  0.0000, -1.0000,  0.0000,\n",
      "          -1.0000,  0.0000,  0.0000],\n",
      "         [ 2.0000, 10.0000,  9.0000,  8.0000,  7.0000,  6.0000,  5.0000,\n",
      "           4.0000,  3.0000,  1.0000],\n",
      "         [ 9.0000,  7.0000,  7.0000,  5.0000,  5.0000,  3.0000,  3.0000,\n",
      "           1.0000,  1.0000, -1.0000]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# === Input: (batch=2, channels=3, length=12)\n",
    "vector_x = torch.tensor([\n",
    "    [  # Sample 1\n",
    "        [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 0.0],\n",
    "        [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0],\n",
    "        [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0]\n",
    "    ],\n",
    "    [  # Sample 2\n",
    "        [0.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "        [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0]\n",
    "    ]\n",
    "])  # Shape: (2, 3, 12)\n",
    "\n",
    "# Same kernel as manual\n",
    "kernel = torch.tensor([\n",
    "    [[-1.0,  0.0,  1.0],   [0.5, 0.0, -0.5], [1.0, 1.0, 1.0]],\n",
    "    [[1.0,  1.0, -1.0],    [0.0, 1.0, 0.0],  [-1.0, 0.0, 1.0]],\n",
    "    [[0.0,  1.0,  0.0],    [1.0, -1.0, 1.0], [0.0, -1.0, 0.0]]\n",
    "])\n",
    "\n",
    "# Define conv layer\n",
    "conv1d = nn.Conv1d(in_channels=3, out_channels=3, kernel_size=3, bias=False)\n",
    "\n",
    "# Manually assign weights\n",
    "with torch.no_grad():\n",
    "    conv1d.weight.copy_(kernel)\n",
    "\n",
    "# Run convolution\n",
    "out_pytorch = conv1d(vector_x)\n",
    "\n",
    "print(\"PyTorch Conv Output Shape:\", out_pytorch.shape)  # (2, 3, 10)\n",
    "print(\"PyTorch Conv Output:\\n\", out_pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e6457a",
   "metadata": {},
   "source": [
    "### For 2D Convolutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81493da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual Batch Output Shape: torch.Size([2, 2, 3, 3])\n",
      "Manual Batch Output:\n",
      " tensor([[[[ 12.5000,   7.5000,  -8.5000],\n",
      "          [ 21.5000,  11.5000, -18.5000],\n",
      "          [ 21.5000,   7.5000, -17.5000]],\n",
      "\n",
      "         [[ -8.5000, -12.5000,  -9.5000],\n",
      "          [ -9.5000, -17.5000,  -9.5000],\n",
      "          [ 10.5000,  17.5000,  11.5000]]],\n",
      "\n",
      "\n",
      "        [[[  9.0000,  10.5000,  12.0000],\n",
      "          [ 16.5000,  18.0000,  19.5000],\n",
      "          [ 24.0000,  25.5000,  27.0000]],\n",
      "\n",
      "         [[  9.0000,  10.5000,  12.0000],\n",
      "          [ 16.5000,  18.0000,  19.5000],\n",
      "          [ 24.0000,  25.5000,  27.0000]]]])\n"
     ]
    }
   ],
   "source": [
    "# === Input tensor: (batch=2, channels=3, H=5, W=5)\n",
    "# Create two different 3-channel 5x5 images\n",
    "input_batch = torch.stack([\n",
    "    torch.stack([\n",
    "        torch.tensor([\n",
    "            [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "            [0.0, 1.0, 2.0, 3.0, 0.0],\n",
    "            [0.0, 4.0, 5.0, 6.0, 0.0],\n",
    "            [0.0, 7.0, 8.0, 9.0, 0.0],\n",
    "            [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "        ]),\n",
    "        torch.ones((5, 5)),                # All 1s\n",
    "        torch.eye(5)                       # Identity\n",
    "    ]),\n",
    "    torch.stack([\n",
    "        torch.full((5, 5), 2.0),           # All 2s\n",
    "        torch.arange(25).view(5, 5).float(),\n",
    "        torch.zeros((5, 5))                # All 0s\n",
    "    ])\n",
    "])  # Shape: (2, 3, 5, 5)\n",
    "\n",
    "# === Kernel: (out_channels=2, in_channels=3, 3x3)\n",
    "kernel = torch.tensor([\n",
    "    [  # Kernel for output channel 0\n",
    "        [[-1.0, 0.0, 1.0],\n",
    "         [-2.0, 0.0, 2.0],\n",
    "         [-1.0, 0.0, 1.0]],\n",
    "        [[0.0, 0.0, 0.0],\n",
    "         [0.5, 0.5, 0.5],\n",
    "         [0.0, 0.0, 0.0]],\n",
    "        [[1.0, 0.0, -1.0],\n",
    "         [0.0, 0.0,  0.0],\n",
    "         [-1.0, 0.0, 1.0]]\n",
    "    ],\n",
    "    [  # Kernel for output channel 1\n",
    "        [[1.0, 1.0, 1.0],\n",
    "         [0.0, 0.0, 0.0],\n",
    "         [-1.0, -1.0, -1.0]],\n",
    "        [[0.0, 0.5, 0.0],\n",
    "         [0.0, 0.5, 0.0],\n",
    "         [0.0, 0.5, 0.0]],\n",
    "        [[0.0, 0.0, 0.0],\n",
    "         [1.0, -1.0, 1.0],\n",
    "         [0.0, 0.0, 0.0]]\n",
    "    ]\n",
    "])  # Shape: (2, 3, 3, 3)\n",
    "\n",
    "def conv2d_multi_batch(x, k):\n",
    "    B, C, H, W = x.shape\n",
    "    OC, IC, KX, KY = k.shape\n",
    "    OX, OY = H - KX + 1, W - KY + 1\n",
    "    out = torch.zeros((B, OC, OX, OY))\n",
    "\n",
    "    for b in range(B):\n",
    "        for oc in range(OC):\n",
    "            for ox in range(OX):\n",
    "                for oy in range(OY):\n",
    "                    for ic in range(IC):\n",
    "                        for kx in range(KX):\n",
    "                            for ky in range(KY):\n",
    "                                out[b, oc, ox, oy] += x[b, ic, ox + kx, oy + ky] * k[oc, ic, kx, ky]\n",
    "    return out\n",
    "\n",
    "# Run manual convolution\n",
    "manual_output = conv2d_multi_batch(input_batch, kernel)\n",
    "print(\"Manual Batch Output Shape:\", manual_output.shape)\n",
    "print(\"Manual Batch Output:\\n\", manual_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afe1438a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Batch Output Shape: torch.Size([2, 2, 3, 3])\n",
      "PyTorch Batch Output:\n",
      " tensor([[[[ 12.5000,   7.5000,  -8.5000],\n",
      "          [ 21.5000,  11.5000, -18.5000],\n",
      "          [ 21.5000,   7.5000, -17.5000]],\n",
      "\n",
      "         [[ -8.5000, -12.5000,  -9.5000],\n",
      "          [ -9.5000, -17.5000,  -9.5000],\n",
      "          [ 10.5000,  17.5000,  11.5000]]],\n",
      "\n",
      "\n",
      "        [[[  9.0000,  10.5000,  12.0000],\n",
      "          [ 16.5000,  18.0000,  19.5000],\n",
      "          [ 24.0000,  25.5000,  27.0000]],\n",
      "\n",
      "         [[  9.0000,  10.5000,  12.0000],\n",
      "          [ 16.5000,  18.0000,  19.5000],\n",
      "          [ 24.0000,  25.5000,  27.0000]]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Same input as above (2, 3, 5, 5)\n",
    "input_batch_pt = input_batch.clone()\n",
    "\n",
    "# Create Conv2d: 3 input → 2 output channels\n",
    "conv2d = nn.Conv2d(in_channels=3, out_channels=2, kernel_size=3, bias=False)\n",
    "\n",
    "# Set the weights to match\n",
    "with torch.no_grad():\n",
    "    conv2d.weight.copy_(kernel)\n",
    "\n",
    "# Run PyTorch convolution\n",
    "output_pt = conv2d(input_batch_pt)\n",
    "\n",
    "print(\"PyTorch Batch Output Shape:\", output_pt.shape)\n",
    "print(\"PyTorch Batch Output:\\n\", output_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6042102a",
   "metadata": {},
   "source": [
    "# Some Notes\n",
    "- Output, filters, and input have some indices that go to the other component. For example, number of input channel is independent of number of output channel for the input and output date. However, input and output channels are used by the filter. So take note of that.\n",
    "- In the 2D convolution with batch size, the sequence of for loop by default is:\n",
    "    - Batch > output channel > output x > output y > input channel > kernel x > kernel y\n",
    "    - The input index is inferred based on the output and kernel indices\n",
    "    - This is the *output centric* indexing\n",
    "- The inner-most loops change the kernel indices frequently. So the kernel changes most frequently for every loop iteration.\n",
    "- Also, observe that for *output centric* indexing, the output changes the slowest too. This is similar to output-stationary.\n",
    "- Output size of the tensor (after the channel) is always pre-determined already.\n",
    "- There are alaways $n_\\textrm{chin} \\times n_\\textrm{chout}$ filters. But in English, there are always $n_\\textrm{chin}$ filter for every output channel. Moreoever, they are each filter is unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8649f81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
