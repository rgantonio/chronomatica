{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5f5ff11-c855-483e-9c97-a3a967c28a90",
   "metadata": {},
   "source": [
    "# ResNet50 with HDC\n",
    "- Here we use vanilla ResNet50 that is unquantized to check and see how it fairs with HDC\n",
    "- It's an adaptation of the CNN+FSL but with the ResNet50 architecture for the CNN block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc7d833-faa0-460c-87af-773f7a86fe89",
   "metadata": {},
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4b3ac94c-0802-40c5-b389-aa82605442bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T16:35:44.184927Z",
     "iopub.status.busy": "2025-06-01T16:35:44.184490Z",
     "iopub.status.idle": "2025-06-01T16:35:44.190130Z",
     "shell.execute_reply": "2025-06-01T16:35:44.189141Z",
     "shell.execute_reply.started": "2025-06-01T16:35:44.184895Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.resnet import ResNet, Bottleneck\n",
    "from torch.quantization import QuantStub, DeQuantStub\n",
    "import torch.quantization\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1873370-3efd-4a47-9ad3-fa01db1a9628",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T13:48:16.124498Z",
     "iopub.status.busy": "2025-06-01T13:48:16.123780Z",
     "iopub.status.idle": "2025-06-01T13:48:16.131074Z",
     "shell.execute_reply": "2025-06-01T13:48:16.130267Z",
     "shell.execute_reply.started": "2025-06-01T13:48:16.124458Z"
    }
   },
   "source": [
    "# GPU Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f160313c-2648-4949-a7a7-ad500ba4242e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T13:48:16.132736Z",
     "iopub.status.busy": "2025-06-01T13:48:16.132165Z",
     "iopub.status.idle": "2025-06-01T13:48:17.093143Z",
     "shell.execute_reply": "2025-06-01T13:48:17.092387Z",
     "shell.execute_reply.started": "2025-06-01T13:48:16.132708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = QuantizableResNet50()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f'Using {torch.cuda.device_count()} GPUs')\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1d6fa6-de3c-49bb-80dc-9b4c829f893f",
   "metadata": {},
   "source": [
    "# Loading Presaved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86687714-e7df-4a13-b217-a144ffb46528",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T13:48:27.525222Z",
     "iopub.status.busy": "2025-06-01T13:48:27.524751Z",
     "iopub.status.idle": "2025-06-01T13:48:27.738345Z",
     "shell.execute_reply": "2025-06-01T13:48:27.737649Z",
     "shell.execute_reply.started": "2025-06-01T13:48:27.525186Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(\"vanilla_resnet50_cifar100.pth\", map_location=device)\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1359607-722e-4efd-beb6-3924435f30d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T13:52:05.108586Z",
     "iopub.status.busy": "2025-06-01T13:52:05.108143Z",
     "iopub.status.idle": "2025-06-01T13:52:05.116334Z",
     "shell.execute_reply": "2025-06-01T13:52:05.115439Z",
     "shell.execute_reply.started": "2025-06-01T13:52:05.108557Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): QuantizableResNet50(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): Identity()\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=100, bias=True)\n",
       "    (quant): QuantStub()\n",
       "    (dequant): DeQuantStub()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edc47f4-98eb-48a8-9af4-1190e2d073d5",
   "metadata": {},
   "source": [
    "# Hook to Extract Maxpool Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60490ce8-4b08-4e91-8db1-520032506fea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T13:59:42.933633Z",
     "iopub.status.busy": "2025-06-01T13:59:42.933189Z",
     "iopub.status.idle": "2025-06-01T13:59:42.937502Z",
     "shell.execute_reply": "2025-06-01T13:59:42.936814Z",
     "shell.execute_reply.started": "2025-06-01T13:59:42.933604Z"
    }
   },
   "outputs": [],
   "source": [
    "# Placeholder for feature map\n",
    "activation = {}\n",
    "\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98185ca-1de0-4efe-8310-8c35bbb75290",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T13:59:53.622914Z",
     "iopub.status.busy": "2025-06-01T13:59:53.622439Z",
     "iopub.status.idle": "2025-06-01T13:59:53.628128Z",
     "shell.execute_reply": "2025-06-01T13:59:53.627300Z",
     "shell.execute_reply.started": "2025-06-01T13:59:53.622881Z"
    }
   },
   "outputs": [],
   "source": [
    "model.module.avgpool.register_forward_hook(get_activation('avgpool'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61e3b7b-fd7a-4fcf-9ffc-442ee9e04820",
   "metadata": {},
   "source": [
    "# Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be7cc709-df1f-41d3-863c-32dd2aaef809",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T14:12:31.789630Z",
     "iopub.status.busy": "2025-06-01T14:12:31.789192Z",
     "iopub.status.idle": "2025-06-01T14:12:32.655100Z",
     "shell.execute_reply": "2025-06-01T14:12:32.654312Z",
     "shell.execute_reply.started": "2025-06-01T14:12:31.789595Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Dataset setup (no batching)\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08f2841a-1e5b-4e44-9e20-3dd8c7293289",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T14:12:33.314001Z",
     "iopub.status.busy": "2025-06-01T14:12:33.313564Z",
     "iopub.status.idle": "2025-06-01T14:12:33.317270Z",
     "shell.execute_reply": "2025-06-01T14:12:33.316538Z",
     "shell.execute_reply.started": "2025-06-01T14:12:33.313972Z"
    }
   },
   "outputs": [],
   "source": [
    "pooled_outputs = []\n",
    "n_collected = 0\n",
    "max_samples = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "179f3a41-4dff-4610-906c-c01ff462c7a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T15:24:59.910332Z",
     "iopub.status.busy": "2025-06-01T15:24:59.909872Z",
     "iopub.status.idle": "2025-06-01T15:24:59.914295Z",
     "shell.execute_reply": "2025-06-01T15:24:59.913488Z",
     "shell.execute_reply.started": "2025-06-01T15:24:59.910300Z"
    }
   },
   "outputs": [],
   "source": [
    "# === 3. Dictionary: class_label -> list of feature tensors ===\n",
    "N = 100  # number of items per class\n",
    "class_features = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6884b465-fd0f-4b59-9b23-573c3569791d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T15:25:01.492199Z",
     "iopub.status.busy": "2025-06-01T15:25:01.491772Z",
     "iopub.status.idle": "2025-06-01T15:28:20.342638Z",
     "shell.execute_reply": "2025-06-01T15:28:20.341576Z",
     "shell.execute_reply.started": "2025-06-01T15:25:01.492167Z"
    }
   },
   "outputs": [],
   "source": [
    "# === 4. Loop through testset to populate dictionary ===\n",
    "with torch.no_grad():\n",
    "    for idx in range(len(testset)):\n",
    "        image, label = testset[idx]\n",
    "\n",
    "        if len(class_features[label]) >= N:\n",
    "            continue\n",
    "\n",
    "        input_tensor = image.unsqueeze(0).to(device)  # [1, 3, 32, 32]\n",
    "        _ = model(input_tensor)\n",
    "\n",
    "        pooled = activation['avgpool'].squeeze().cpu()  # [2048]\n",
    "        class_features[label].append(pooled)\n",
    "\n",
    "        # Stop early if we have enough from every class\n",
    "        if all(len(v) >= N for v in class_features.values()) and len(class_features) == 100:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "57a8bf04-4616-493b-b171-9ec81eeb646e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T15:28:20.344303Z",
     "iopub.status.busy": "2025-06-01T15:28:20.343948Z",
     "iopub.status.idle": "2025-06-01T15:28:20.348802Z",
     "shell.execute_reply": "2025-06-01T15:28:20.348080Z",
     "shell.execute_reply.started": "2025-06-01T15:28:20.344273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected features for 100 classes.\n",
      "Example: Class 0 has 100 feature vectors\n",
      "Feature vector shape: torch.Size([2048])\n"
     ]
    }
   ],
   "source": [
    "# === 5. Check and use ===\n",
    "print(f\"Collected features for {len(class_features)} classes.\")\n",
    "print(f\"Example: Class 0 has {len(class_features[0])} feature vectors\")\n",
    "print(f\"Feature vector shape: {class_features[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b68418dd-62d1-46cb-b80d-df30b4bcb578",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T14:29:49.620821Z",
     "iopub.status.busy": "2025-06-01T14:29:49.620368Z",
     "iopub.status.idle": "2025-06-01T14:29:49.625015Z",
     "shell.execute_reply": "2025-06-01T14:29:49.624273Z",
     "shell.execute_reply.started": "2025-06-01T14:29:49.620789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9fb7542b-7a7f-4253-8eb0-15d16cb90dfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T16:07:33.631625Z",
     "iopub.status.busy": "2025-06-01T16:07:33.630716Z",
     "iopub.status.idle": "2025-06-01T16:07:33.638007Z",
     "shell.execute_reply": "2025-06-01T16:07:33.637283Z",
     "shell.execute_reply.started": "2025-06-01T16:07:33.631571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    }
   ],
   "source": [
    "print(len(class_features[99][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b79245-83ea-49ca-9ed6-cb502a69c9ff",
   "metadata": {},
   "source": [
    "# HDC training Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "97280626-7307-49f5-af0b-231225afa077",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T16:07:43.030370Z",
     "iopub.status.busy": "2025-06-01T16:07:43.029359Z",
     "iopub.status.idle": "2025-06-01T16:07:43.062688Z",
     "shell.execute_reply": "2025-06-01T16:07:43.061842Z",
     "shell.execute_reply.started": "2025-06-01T16:07:43.030317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048, 512])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the dimensions\n",
    "input_dim = len(class_features[0][0])   # e.g., 512 channels × 7 × 7\n",
    "output_dim = 512    # your projected size\n",
    "\n",
    "# Randomly generate +1 and -1 entries\n",
    "projection_matrix = (torch.randint(0, 2, (input_dim, output_dim)) * 2 - 1).float()  # values: [0, 1] → [−1, 1]\n",
    "projection_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "92ec25a5-9af5-49ce-81ca-863c6185e497",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T16:13:54.075997Z",
     "iopub.status.busy": "2025-06-01T16:13:54.075443Z",
     "iopub.status.idle": "2025-06-01T16:13:54.626411Z",
     "shell.execute_reply": "2025-06-01T16:13:54.625102Z",
     "shell.execute_reply.started": "2025-06-01T16:13:54.075966Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training HDC: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 185.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# Some fixed parameters\n",
    "NUM_CLASSES = 100\n",
    "HV_DIM = 512\n",
    "NUM_TRAIN_SAMPLES = 50\n",
    "\n",
    "# Initialize class HVs\n",
    "class_hvs_bin = {}\n",
    "class_hvs_int = {}\n",
    "\n",
    "# Iterate per class with tqdm\n",
    "for class_item in tqdm(range(NUM_CLASSES), desc=\"Training HDC\"):\n",
    "\n",
    "    # Initialize class hv\n",
    "    class_hv = torch.zeros(HV_DIM)\n",
    "\n",
    "    for item in range(NUM_TRAIN_SAMPLES):\n",
    "        query_v = class_features[class_item][item] @ projection_matrix\n",
    "        class_hv = class_hv + query_v\n",
    "\n",
    "    label = class_item\n",
    "    class_hvs_int[label] = class_hv\n",
    "\n",
    "    # Sign magnitude\n",
    "    class_hv_bin = torch.sign(class_hv)\n",
    "    class_hvs_bin[label] = class_hv_bin\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412d6531-193c-4a89-a3a9-95e0c248b270",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T16:14:19.810538Z",
     "iopub.status.busy": "2025-06-01T16:14:19.810061Z",
     "iopub.status.idle": "2025-06-01T16:14:19.815797Z",
     "shell.execute_reply": "2025-06-01T16:14:19.815048Z",
     "shell.execute_reply.started": "2025-06-01T16:14:19.810510Z"
    }
   },
   "source": [
    "# HDC Testing on Trained Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "48a03f27-cc84-48d1-8e49-d35813c62bc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T16:40:40.590361Z",
     "iopub.status.busy": "2025-06-01T16:40:40.589931Z",
     "iopub.status.idle": "2025-06-01T16:40:40.594737Z",
     "shell.execute_reply": "2025-06-01T16:40:40.594050Z",
     "shell.execute_reply.started": "2025-06-01T16:40:40.590332Z"
    }
   },
   "outputs": [],
   "source": [
    "def sim_search(class_hvs, q_hv):\n",
    "    sim_score = -2\n",
    "    target_label = -9\n",
    "    for i in range(len(class_hvs)):\n",
    "        cos_sim  = F.cosine_similarity(q_hv, class_hvs[i], dim=0)\n",
    "        if cos_sim > sim_score:\n",
    "            sim_score = cos_sim\n",
    "            target_label = i\n",
    "    return sim_score, target_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c425f88d-22d8-41a5-bfaf-9336d54c95ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T16:41:37.998063Z",
     "iopub.status.busy": "2025-06-01T16:41:37.997607Z",
     "iopub.status.idle": "2025-06-01T16:42:29.068762Z",
     "shell.execute_reply": "2025-06-01T16:42:29.066536Z",
     "shell.execute_reply.started": "2025-06-01T16:41:37.998022Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating classes: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:51<00:00,  1.96it/s]\n"
     ]
    }
   ],
   "source": [
    "START_NUM = NUM_TRAIN_SAMPLES\n",
    "MAX_SAMPLES = 100\n",
    "\n",
    "correct_qhv_int = 0\n",
    "correct_qhv_bin = 0\n",
    "\n",
    "for class_set in tqdm(range(NUM_CLASSES), desc=\"Evaluating classes\"):  \n",
    "    for item in range(NUM_TRAIN_SAMPLES):\n",
    "        query_v = class_features[class_set][item] @ projection_matrix\n",
    "        # Compare int style first\n",
    "        _, target_label_int = sim_search(class_hvs_int, query_v)\n",
    "        # Compare bin style 2nd\n",
    "        projected_bin = torch.sign(query_v)\n",
    "        _, target_label_bin = sim_search(class_hvs_bin, projected_bin)\n",
    "\n",
    "        if target_label_int == class_set:\n",
    "            correct_qhv_int += 1\n",
    "\n",
    "        if target_label_bin == class_set:\n",
    "            correct_qhv_bin += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b4a3f069-2651-48a9-b6d0-a9a4aac9aa80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T16:42:40.790187Z",
     "iopub.status.busy": "2025-06-01T16:42:40.789505Z",
     "iopub.status.idle": "2025-06-01T16:42:40.796654Z",
     "shell.execute_reply": "2025-06-01T16:42:40.795901Z",
     "shell.execute_reply.started": "2025-06-01T16:42:40.790140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (int): 0.78\n",
      "Accuracy (bin): 0.75\n"
     ]
    }
   ],
   "source": [
    "TOTAL_TEST = (NUM_TRAIN_SAMPLES)*NUM_CLASSES\n",
    "accuracy_int = correct_qhv_int / TOTAL_TEST\n",
    "accuracy_bin = correct_qhv_bin / TOTAL_TEST\n",
    "print(f\"Accuracy (int): {accuracy_int:.2f}\")\n",
    "print(f\"Accuracy (bin): {accuracy_bin:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592ee09e-d529-4a3d-9a12-6835c85eadf8",
   "metadata": {},
   "source": [
    "# HDC Testing on Untrained Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3cd8f472-7ec2-40fe-b141-60cae9e80814",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T16:43:55.169967Z",
     "iopub.status.busy": "2025-06-01T16:43:55.169340Z",
     "iopub.status.idle": "2025-06-01T16:44:37.629187Z",
     "shell.execute_reply": "2025-06-01T16:44:37.626452Z",
     "shell.execute_reply.started": "2025-06-01T16:43:55.169897Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating classes: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:42<00:00,  2.36it/s]\n"
     ]
    }
   ],
   "source": [
    "START_NUM = NUM_TRAIN_SAMPLES\n",
    "MAX_SAMPLES = 100\n",
    "\n",
    "correct_qhv_int = 0\n",
    "correct_qhv_bin = 0\n",
    "\n",
    "for class_set in tqdm(range(NUM_CLASSES), desc=\"Evaluating classes\"):  \n",
    "    for item in range(START_NUM,MAX_SAMPLES):\n",
    "        query_v = class_features[class_set][item] @ projection_matrix\n",
    "        # Compare int style first\n",
    "        _, target_label_int = sim_search(class_hvs_int, query_v)\n",
    "        # Compare bin style 2nd\n",
    "        projected_bin = torch.sign(query_v)\n",
    "        _, target_label_bin = sim_search(class_hvs_bin, projected_bin)\n",
    "\n",
    "        if target_label_int == class_set:\n",
    "            correct_qhv_int += 1\n",
    "\n",
    "        if target_label_bin == class_set:\n",
    "            correct_qhv_bin += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "450cd2a8-36b8-4ada-bffe-061d6789f5dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T16:44:47.319067Z",
     "iopub.status.busy": "2025-06-01T16:44:47.318534Z",
     "iopub.status.idle": "2025-06-01T16:44:47.327228Z",
     "shell.execute_reply": "2025-06-01T16:44:47.326474Z",
     "shell.execute_reply.started": "2025-06-01T16:44:47.319010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (int): 0.76\n",
      "Accuracy (bin): 0.72\n"
     ]
    }
   ],
   "source": [
    "TOTAL_TEST = (MAX_SAMPLES - NUM_TRAIN_SAMPLES)*NUM_CLASSES\n",
    "accuracy_int = correct_qhv_int / TOTAL_TEST\n",
    "accuracy_bin = correct_qhv_bin / TOTAL_TEST\n",
    "print(f\"Accuracy (int): {accuracy_int:.2f}\")\n",
    "print(f\"Accuracy (bin): {accuracy_bin:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda0b1d9-a682-4949-a818-a8948323dfb2",
   "metadata": {},
   "source": [
    "# Notes\n",
    "- It is interesting to see that ResNet is the better feature extractor and hence the different from vanilla HDC (top-1 accuracy is 76.56 %) is not too far from the CNN+FSL version (top-1 accuracy is 78% int and 75% binary on trained set while we have 76% int and 72% binary on untrained set)\n",
    "- I guess the argument here is that unlike VGG, ResNet CNN architecture is already a very nice feature extractor "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
